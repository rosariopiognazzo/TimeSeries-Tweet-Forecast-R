---
title: "LLMs"
author: "Rosario Pio Gnazzo"
date: "2025-02-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Carica il pacchetto
library(jsonlite)
```

# Dataset più piccolo

```{r}
# Percorso del file (modifica se necessario)
file_path <- "C:/Users/rosar/Desktop/dataset_sintetico3.json"

# Carica il dataset
df <- stream_in(file(file_path))

# Visualizza le prime righe
head(df)
```

```{r}
#correggiamo il formato delle variabili
data <- df %>%
  mutate(userid = as.character(userid),
         following = as.numeric(following),
         followers = as.numeric(followers),
         totaltweets = as.numeric(totaltweets),
         tweetid = as.character(tweetid),
         retweetcount = as.numeric(retweetcount),
         favorite_count = as.numeric(favorite_counts),
         is_retweet = as.factor(is_retweet),
         is_quote_status = as.factor(is_quote_status),
         sentiment = as.factor(sentiment),
         score = as.numeric(score)
  )
```

```{r}
descr <- data %>% 
  select_if(is.numeric) %>% psych::describe()
descr %>% select(-c(vars))
```

```{r}
# Trasformazione logaritmica per variabili con forte asimmetria
data$log_followers <- log1p(data$followers)
data$log_following <- log1p(data$following)
data$log_totaltweets <- log1p(data$totaltweets)
data$log_retweetcount <- log1p(data$retweetcount)
data$log_favorite_count <- log1p(data$favorite_count)
data$log_score <- log1p(data$score)
```

```{r}
# Funzione per identificare outlier con il metodo IQR (Tukey)
detect_outliers_iqr <- function(x) {
  Q1 <- quantile(x, 0.25, na.rm = TRUE)
  Q3 <- quantile(x, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  return(x < lower_bound | x > upper_bound)
}

# Funzione per identificare outlier con lo Z-score
detect_outliers_zscore <- function(x) {
  z_scores <- (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
  return(abs(z_scores) > 3)
}

# Funzione per identificare outlier con il metodo di Hampel
detect_outliers_hampel <- function(x) {
  med <- median(x, na.rm = TRUE)
  mad_val <- mad(x, constant = 1.4826, na.rm = TRUE) # MAD con costante per la normalizzazione
  return(abs(x - med) / mad_val > 3)
}
```

```{r}
p1 <- ggplot(data, aes(x = followers)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "blue", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$followers), 
                            sd = sd(data$followers)), color = "darkblue", size = 1) +
  theme_bw() +
  ggtitle("Followers")

p2 <- ggplot(data, aes(x = totaltweets)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "red", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$totaltweets), 
                            sd = sd(data$totaltweets)), color = "darkred", size = 1) +
  theme_bw() +
  ggtitle("Total Tweets")

p3 <- ggplot(data, aes(x = following)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "purple", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$following), 
                            sd = sd(data$following)), color = "purple4", size = 1) +
  theme_bw() +
  ggtitle("Following")

p4 <- ggplot(data, aes(x = retweetcount)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "brown", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$retweetcount), 
                            sd = sd(data$retweetcount)), color = "brown4", size = 1) +
  theme_bw() +
  ggtitle("Retweetcount")

p5 <- ggplot(data, aes(x = favorite_count)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "orange", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$favorite_count), 
                            sd = sd(data$favorite_count)), color = "orange4", size = 1) +
  theme_bw() +
  ggtitle("Favouritecount")

p6 <- ggplot(data, aes(x = score)) + 
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = "green", alpha = 0.5) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(data$score), 
                            sd = sd(data$score)), color = "darkgreen", size = 1) +
  theme_bw() +
  ggtitle("Score")

grid.arrange(p1, p2, p3, p4, p5, p6, ncol=3)
```

```{r}
# Riorganizzazione dei dati in formato long
df_long <- data %>%
  select(log_followers, log_totaltweets, log_following, 
         log_retweetcount, log_favorite_count, log_score) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

color_palette <- c(
  "log_followers" = "blue",
  "log_totaltweets" = "red",
  "log_following" = "purple",
  "log_retweetcount" = "brown",
  "log_favorite_count" = "orange",
  "log_score" = "green"
)

# Creazione del boxplot unico
ggplot(df_long, aes(y = Variable, x = Value, fill = Variable)) +
  geom_boxplot(alpha = 0.5, outlier.alpha = 0.5, notch = TRUE) +
  theme_bw() +
  ggtitle("Boxplot delle Variabili") +
  scale_fill_manual(values = color_palette)
```

```{r}
# Applicazione delle funzioni a ciascuna variabile numerica
outliers_iqr <- data %>% mutate(across(where(is.numeric), detect_outliers_iqr))
outliers_zscore <- data %>% mutate(across(where(is.numeric), detect_outliers_zscore))
outliers_hampel <- data %>% mutate(across(where(is.numeric), detect_outliers_hampel))

# Creazione di una tabella riepilogativa degli outlier
summary_outliers <- data.frame(
  Variable = names(data %>% select(where(is.numeric))),
  IQR_Outliers = sapply(data %>% select(where(is.numeric)), function(x) sum(detect_outliers_iqr(x), na.rm = TRUE)),
  ZScore_Outliers = sapply(data %>% select(where(is.numeric)), function(x) sum(detect_outliers_zscore(x), na.rm = TRUE)),
  Hampel_Outliers = sapply(data %>% select(where(is.numeric)), function(x) sum(detect_outliers_hampel(x), na.rm = TRUE))
)

print(summary_outliers)
```

```{r}
library(reshape2)

melted_outliers <- melt(summary_outliers, id.vars = "Variable")
ggplot(melted_outliers, aes(x = Variable, y = value, fill = variable)) + 
  geom_bar(stat = "identity", position = "dodge") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Numero di outlier per metodo e variabile")
```

```{r}
plot_density_comparison <- function(data, log_var_name, color) {
  
  # Creazione dei dati per le due distribuzioni
  df1 <- data.frame(Value = data[[log_var_name]], Type = paste(log_var_name, "(Log)"))
  df2 <- data %>% 
    filter(!detect_outliers_hampel(.data[[log_var_name]])) %>% 
    transmute(Value = .data[[log_var_name]], Type = paste(log_var_name, "(Log) - No Outliers"))
  
  # Unione dei dataset
  df_plot <- bind_rows(df1, df2)
  
  
  # Plot delle densità con ggplot2
  ggplot(df_plot, aes(x = Value, color = Type)) +
    geom_histogram(aes(y = after_stat(density)),
                 bins = 30, fill = color, alpha = 0.2) +
    geom_density(linewidth=1.3) +
    scale_color_manual(values = c(paste(color,"4"), paste(color,"4"))) +
    facet_wrap(~Type, scales = "free") + 
    theme_bw() + 
    theme(legend.position = "bottom")
}
```

```{r, fig.height=15, fig.width=25}
p1<-plot_density_comparison(data,"log_followers", "blue")
p2<-plot_density_comparison(data,"log_totaltweets", "red")
p3<-plot_density_comparison(data,"log_following", "purple")
p4<-plot_density_comparison(data,"log_retweetcount", "brown")
p5<-plot_density_comparison(data,"log_favorite_count", "orange")
p6<-plot_density_comparison(data, "log_score", "green")


grid.arrange(p1, p2, p3, p4, p5, p6, ncol=2)

```

```{r, fig.height=10, fig.width=10}
df <- data %>% filter(!detect_outliers_hampel(log_followers))
p7<-ggqqplot(df$log_followers, 
         color = "blue",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_followers & No-Outliers")

df <- data %>% filter(!detect_outliers_hampel(log_totaltweets))
p8 <- ggqqplot(df$log_totaltweets, 
         color = "red",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_totaltweets & No-Outliers")

df <- data %>% filter(!detect_outliers_hampel(log_following)) 
p9 <- ggqqplot(df$log_following, 
         color = "purple",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_following & No-Outliers")

df <- data %>% filter(!detect_outliers_hampel(log_retweetcount))
p10 <- ggqqplot(df$log_retweetcount, 
         color = "brown",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_retweetcount & No-Outliers")

df <- data %>% filter(!detect_outliers_hampel(log_favorite_count))
p11 <- ggqqplot(df$log_favorite_count, 
         color = "orange",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_favorite_count & No-Outliers")

df <- data %>% filter(!detect_outliers_hampel(log_score))
p12 <- ggqqplot(df$log_score, 
         color = "green",       # Colore dei punti
         ggtheme = theme_bw(),
         title = "Q-Q plot: log_score & No-Outliers")

grid.arrange(p7,
             p8,
             p9,
             p10,
             p11,
             p12, ncol = 3)
```

```{r}
## Fatta a mano
x <- data %>% filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  summarise( N = n(),
             M = mean(log_followers),
             sd = sd(log_followers))

a <- numeric(4)
for(i in 1:4){
  a[i] <- qnorm(0.2*i, mean = x$M, sd=x$sd)
}

a

# Determinare il numero di elementi del campione che cadono nei singoli intervalli:
r <- 5
nint <- numeric(r)
nint[1] <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  filter(log_followers < a[1]) %>%
  summarise( N = n())%>%
  pull(N)
nint[2] <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  filter(log_followers >= a[1] & log_followers < a[2]) %>%
  summarise( N = n())%>%
  pull(N)
nint[3] <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  filter(log_followers >= a[2] & log_followers < a[3]) %>%
  summarise( N = n())%>%
  pull(N)
nint[4] <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  filter(log_followers >= a[3] & log_followers < a[4]) %>%
  summarise( N = n())%>%
  pull(N)
nint[5] <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers) %>%
  filter(log_followers >= a[4]) %>%
  summarise( N = n())%>%
  pull(N)


chisq.test(nint, p = rep(0.2, length(nint)))

df <- data %>% 
  filter(!detect_outliers_hampel(log_followers)) %>%
  select(log_followers)

nortest::lillie.test(df$log_followers)
```

```{r, fig.height=10}
library(GGally)

data %>%
  select(log_followers, log_following, log_totaltweets, log_retweetcount, log_favorite_count, log_score) %>%
  GGally::ggpairs(
    upper = list(continuous = wrap("cor", size = 4)),
    lower = list(continuous = wrap("smooth", color = "gray60")),
    diag = list(continuous = wrap("densityDiag", fill = "lightblue"))
  ) +
  theme_bw()
```

```{r}
data %>%
  select(followers, following, totaltweets, retweetcount, favorite_count, score) %>%
  GGally::ggpairs(
    upper = list(continuous = wrap("cor", size = 4)),
    lower = list(continuous = wrap("smooth", color = "gray60")),
    diag = list(continuous = wrap("densityDiag", fill = "lightblue"))
  ) +
  theme_bw()
```

```{r}
model1 <- lm(score ~ log_followers + log_following + log_totaltweets + 
              log_retweetcount + log_favorite_count, data = data)

# Riepilogo del modello
summary(model1)
```

```{r}
df <- data %>%
  select(score, log_followers, log_following, log_totaltweets, log_retweetcount, log_favorite_count, is_retweet, is_quote_status, sentiment)

model2 <- lm(score ~ ., data = df)

# Riepilogo del modello
summary(model2)
```

```{r}
df <- data %>%
  select(following, followers, totaltweets, retweetcount, favorite_count, is_retweet, is_quote_status, sentiment, score)

model <- lm(score ~ ., data = df)

summary(model)
```

```{r}
library(nnet)

# Modello multinomiale: sentiment come variabile dipendente
model_multinom <- multinom(sentiment ~ ., data = df)

# Sommario del modello
summary(model_multinom)
```

# Dataset più grande

```{r}
# Percorso del file (modifica se necessario)
file_path <- "C:/Users/rosar/Desktop/dataset_sintetico2.json"

# Carica il dataset
df <- stream_in(file(file_path))

# Visualizza le prime righe
head(df)
```
