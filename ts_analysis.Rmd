---
title: "Time_series_analysis"
author: "Rosario Pio Gnazzo"
date: "2024-12-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message=FALSE, 
                      warning=FALSE, 
                      fig.align='center', fig.width = 10)
options(xts_check_TZ = FALSE)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(highfrequency)
library(xts)
library(forecast)
library(lubridate)
```

```{r}
#pc casa
#Sentiment_fr_tweet_2023 <- read_csv2("C:/Users/rosar/Desktop/UNISA/Magistrale - Informatica/SAD/Sentiment_fr_tweet_2023.csv")

#laptop
Sentiment_fr_tweet_2023 <- read_csv2("C:/Users/rosar/Desktop/SAD/Sentiment_fr_tweet_2023.csv")


dataset <- Sentiment_fr_tweet_2023

dataset <- dataset %>%
  mutate(userid = as.character(userid),
         following = as.numeric(following),
         followers = as.numeric(followers),
         totaltweets = as.numeric(totaltweets),
         tweetid = as.character(tweetid),
         retweetcount = as.numeric(retweetcount),
         favorite_count = as.numeric(favorite_count),
         is_retweet = as.factor(ifelse(is_retweet == FALSE, 0, 1)),
         is_quote_status = as.factor(ifelse(is_quote_status == FALSE, 0, 1)),
         sentiment = as.factor(sentiment),
         score = as.numeric(score),
         score_std = scale(score))
```

### Time Series Analysis della variabile *score*

```{r}
# Funzione per creare oggetti <ts> e visualizzare serie storiche di una variabile numerica rispeto ad una categoriale indicando in che unità di tempo visualizzarla
# create_ts_plot <- function(data, var_num, var_fact, var_temp, tmp, diff) {
#   # dati ordinati
#   data <- data %>%
#     arrange(!!sym(var_temp))
#   
#   # Creazione della lista di serie temporali per ogni categoria della variabile categoriale
#   series_list <- split(data, data[[var_fact]])
#   
#   # facciamo l'aggregazione omogenea per ogni categoria
#   series_homogeneous <- lapply(series_list, function(group) {
#     # Conversione in oggetto xts
#     ts_data <- xts(group[[var_num]], order.by = group[[var_temp]])
#     
#     # Estrazione delle unità di tempo e del periodo
#     align_by <- tmp[1] # Es. "hours", "minutes"
#     align_period <- tmp[2] # Es. 1, 2, ecc.
#     
#     # Aggregazione
#     aggregated_data <- aggregateTS(ts_data, alignBy = align_by, alignPeriod = as.integer(align_period))
#     
#     # Creazione di un dataframe con i dati aggregati
#     data.frame(
#       time = as.POSIXct(index(aggregated_data)),
#       value = as.numeric(aggregated_data)
#     )
#   })
#   
#   # Combiniamo i dati aggregati
#   df_homogeneous <- bind_rows(
#     Map(function(data, category) {
#       data$category <- category
#       data
#     }, series_homogeneous, names(series_homogeneous))
#   )
#   
#   # Calcolo delle differenze, se richiesto
#   if (diff) {
#     df_homogeneous <- df_homogeneous %>%
#       group_by(category) %>%
#       arrange(time) %>%  # Riordina per sicurezza
#       mutate(value = value - lag(value)) %>%  # Differenza rispetto al valore precedente
#       ungroup()
#   }
#   
#   # Creazione del grafico
#   p <- ggplot(df_homogeneous, aes(x = time, y = value, color = category)) +
#     geom_line() +
#     facet_wrap(~ category, scales = "free_y") +
#     labs(
#       title = ifelse(diff, 
#                      "Variazione della Variabile Numerica nel Tempo", 
#                      "Andamento della Variabile Numerica nel Tempo"),
#       x = "Tempo",
#       y = ifelse(diff, "Variazione", "Valore")
#     ) +
#     theme_minimal()
#   
#   print(p)#plotto
#   
#   return(series_homogeneous)
# }
```

Osserviamo come la variabile _score_ cambia nel tempo per le tre classi della variabile _sentiment_ (neg, neu e pos):

```{r}
# Eseguiamo la funzione
# scoreTS <- create_ts_plot(
#   data = dataset, 
#   var_num = "score", 
#   var_fact = "sentiment", 
#   var_temp = "tweetcreatedts", 
#   tmp = c("seconds", 1), 
#   diff = FALSE
# )

df <- dataset %>% select(tweetcreatedts, score_std, sentiment)

ggplot(data = df, aes(x = tweetcreatedts, y=score_std)) +
  geom_line(aes(colour = sentiment))+
  facet_grid(~sentiment)
```

*Per semplicità visualizzo solo NEG*

```{r}
ts_data <- xts(df$score_std, order.by = df$tweetcreatedts)
score30 <- aggregateTS(ts_data, alignBy = "minutes", alignPeriod = 30)
score1h <- aggregateTS(ts_data, alignBy = "hours", alignPeriod = 1)
score6h <- aggregateTS(ts_data, alignBy = "hours", alignPeriod = 6)
score12h <- aggregateTS(ts_data, alignBy = "hours", alignPeriod = 12)

autoplot(score30)+theme_bw()
autoplot(score1h)+theme_bw()
autoplot(score6h)+theme_bw()
autoplot(score12h)+theme_bw()
```

Le serie storiche mostrano mostrano dati ad *alta frequenza*, valutiamo se si distribuiscono come *white noise* e per farlo osserviamo *partial ACF* che ci indica le eventuali autocorrelazioni dirette fra i vari lag:
```{r}
negative <- df %>% filter(sentiment=="neg")%>% select(tweetcreatedts, score_std)
names(negative) <- c("time", "value")
Pacf(negative$value,lag.max = 1000)

# positive <- df %>% filter(sentiment=="pos")%>% select(tweetcreatedts, score)
# names(positive) <- c("time", "value")
# Pacf(positive$value,lag.max = 1000)
# 
# neutral <- df %>% filter(sentiment=="neu")%>% select(tweetcreatedts, score)
# names(neutral) <- c("time", "value")
# Pacf(neutral$value,lag.max = 1000)
```

Sembrerebbe esseci nel primo periodo la presenza di un trend che poi termina intorno il lag 50, persiste successivamente una caratteristica sottostante che rende le serie non white noise.

-   _Lavorare sull'identificare un modo per catturare separatamente le due caratteristiche_
-   Per gestire l'alta variabilità potremmo usare trasformata Box-Cox (aggregando anche i dati)

Per analizzare al meglio le serie storiche identifichiamo i possibili outliers utilizzando: *Algoritmo Brownlees-Gallo*:

```{r}
detect_outliers <- function(data, gamma, delta, k) {
  # Verifica input
  if (!is.data.frame(data) || !all(c("time", "value") %in% names(data))) {
    stop("L'input deve essere un data.frame con colonne 'time' e 'value'.")
  }
  if (!is.numeric(data$value)) {
    stop("La colonna 'value' deve contenere valori numerici.")
  }
  if (!is.numeric(gamma) || gamma < 0) {
    stop("Il parametro gamma deve essere un valore numerico non negativo.")
  }
  if (!is.numeric(delta) || delta < 0 || delta > 0.5) {
    stop("Il parametro delta deve essere un valore numerico compreso tra 0 e 0.5.")
  }
  if (!is.numeric(k) || k <= 0 || k %% 1 != 0) {
    stop("Il parametro k deve essere un intero positivo.")
  }

  prices <- data$value
  n <- length(prices)  # Lunghezza della serie
  outliers <- rep(FALSE, n)  # Vettore per memorizzare gli outliers

  for (i in seq_len(n)) {
    # Determinazione dell'intorno
    if (i <= k / 2) {
      # Prima parte della giornata
      window <- prices[1:min(n, k)]
    } else if (i > (n - k / 2)) {
      # Ultima parte della giornata
      window <- prices[max(1, n - k + 1):n]
    } else {
      # Parte centrale della giornata
      half_k <- floor(k / 2)
      window <- prices[(i - half_k):(i + half_k)]
    }

    # Calcolo della media troncata e della deviazione standard
    trimmed_mean <- mean(window, trim = delta)
    std_dev <- sd(window)

    # Evitare varianze nulle
    threshold <- 3 * std_dev + gamma

    # Verifica della condizione
    if (abs(prices[i] - trimmed_mean) >= threshold) {
      outliers[i] <- TRUE  # Marca l'osservazione come outlier
    }
  }

  # # Creazione del plot
  # plot(data$time, data$value, type = "o", col = ifelse(outliers, "red", "black"), pch = 19, main = "Serie Temporale con Outliers",
  #      xlab = "Tempo", ylab = "Valore")
  # legend("topright", legend = c("Normale", "Outlier"), col = c("black", "red"), pch = 19)

  # Rimuovere gli outliers
  data_no_outliers <- data[!outliers, ]

  
  # # Creazione del plot senza outliers
  # plot(data_no_outliers$time, data_no_outliers$value, col = "black", main = "Serie Temporale senza Outliers",
  #      xlab = "Tempo", ylab = "Valore")

  return(list(outliers = outliers, data_no_outliers = data_no_outliers))
}

# Parametri dell'algoritmo
gamma <- 0.01
delta <- 0.2
k <- 60
#Identificazione degli outliers
outliers <- detect_outliers(negative, gamma, delta, k)
```

```{r}

negative$outlier <- outliers$outliers
ggplot(negative, aes(x = time, y = value, color = outlier)) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = c("grey50", "red"), labels = c("Normale", "Outlier")) +
    labs(title = "Serie Temporale con Outliers", x = "Tempo", y = "Valore", color = "Legenda") +
    theme_minimal()

# ggplot(data= outliers$data_no_outliers, aes(x = time, y = value)) +
#     geom_line(color = "black") +
#     labs(title = "Serie Temporale senza Outliers", x = "Tempo", y = "Valore") +
#     theme_minimal()

df_out <- negative %>% filter(outlier==TRUE)
ggplot(data= df_out, aes(x = time, y = value)) +
    geom_line(color = "red") +
    labs(title = "Serie Temporale degli Outliers", x = "Tempo", y = "Valore") +
    theme_minimal()

# checkresiduals(df_out$value) qualche errore poiché ci sono NAs
acf(df_out$value, lag.max = 1000)
Pacf(df_out$value, lag.max = 1000)
Box.test(df_out$value, type = "Ljung-Box")
```

Non segue una distribuzione strettamente white noise quindi c'è qualche caratteristica sottostante nell'andamento dei valori anomali nel tempo.

```{r}
# acf(scoreTS$neg$value, lag.max = 100, main = "Autocorrelazione (Sentiment: neg)")
# acf(scoreTS$neu$value, lag.max = 100, main = "Autocorrelazione (Sentiment: neu)")
# acf(scoreTS$pos$value, lag.max = 100, main = "Autocorrelazione (Sentiment: pos)")

# pacf(scoreTS$neg$value, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: neg)")
# pacf(scoreTS$neu$value, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: neu)")
# pacf(scoreTS$pos$value, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: pos)")
```

### Analisi per intervalli di 30 minuti delle frequenze di tweet

Potrebbe essere interessante osservare il numero di tweet effettuati in sotto-intervalli temporali rispetto a tutto il range che abbiamo:
```{r}
df_occ <- dataset %>%
  mutate(interval = floor_date(tweetcreatedts, "30 minutes")) %>%
  group_by(interval, sentiment) %>%
  summarise(count = n(), .groups = "drop") %>%
  arrange(interval, sentiment)
```

```{r}
# Grafico a linee
ggplot(df_occ, aes(x = interval, y = count, color = sentiment)) +
  geom_line() +
  labs(
    title = "Conteggio dei Tweet per Sentiment",
    x = "Intervalli di 30 Minuti",
    y = "Numero di Tweet",
    color = "Sentiment"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_datetime(date_breaks = "6 hours", date_labels = "%d-%b %H:%M")
```

Il grafico sembra chiaramente catturare la presenza di periodicità temporale nei dati, per questo motivo
effettuiamo un'analisi statistica per valutarne l'effettiva presenza.

```{r}
# Trasformazione in formato wide perché più comodo
df_occ_wide <- df_occ %>%
  pivot_wider(names_from = sentiment, values_from = count, values_fill = 0)

df_occ_wide

# Creazione delle serie temporali per un sentiment specifico (es. "neg")
neg_ts <- ts(df_occ_wide$neg, start = c(2023, 1), frequency = 48) # 48 intervalli di 30 minuti al giorno
# neu_ts <- ts(df_occ_wide$neu, start = c(2023, 1), frequency = 48) # 48 intervalli di 30 minuti al giorno
# pos_ts <- ts(df_occ_wide$pos, start = c(2023, 1), frequency = 48) # 48 intervalli di 30 minuti al giorno

# seasonplot(neg_ts)
# seasonplot(neu_ts)
# seasonplot(pos_ts)
```

Si nota chiaramente una presenza di periodicità nei dati. Valutiamola quantitativamente:

```{r}
acf(neg_ts, lag.max = 100, main = "Autocorrelazione (Sentiment: neg)")
# acf(neu_ts, lag.max = 100, main = "Autocorrelazione (Sentiment: neu)")
# acf(pos_ts, lag.max = 100, main = "Autocorrelazione (Sentiment: pos)")

# pacf(neg_ts, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: neg)")
# pacf(neu_ts, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: neu)")
# pacf(pos_ts, lag.max = 100, main = "Autocorrelazione parziale (Sentiment: pos)")

```

Il test Ljung-Box valuta se le correlazioni rilevate sono significative, in particolare
se il p-value è piccolo (<0.05), significa che ci sono correlazioni significative nei dati.
```{r}
Box.test(neg_ts, lag = 100, type = "Ljung-Box")
# Box.test(neu_ts, lag = 100, type = "Ljung-Box")
# Box.test(pos_ts, lag = 100, type = "Ljung-Box")
```

## Modello decomposizione migliore

Cerchiamo il miglior modello di decomposizione che possa estarre tutte le caratteristiche dai dati:

```{r}
# Decomposizione della serie temporale
# osservare la componente seasonal per vedere se ci sono pattern ripetuti

neg_ts %>% stl(t.window = 13, s.window = "periodic", robust = TRUE) -> fit
neg_ts %>% decompose(type="multiplicative") -> fit1
# neu_ts %>% decompose(type="multiplicative") -> fit2
# pos_ts %>% decompose(type="multiplicative") -> fit3

# fit %>%
#   autoplot() + xlab("tempo") +
#   ggtitle("Decomposizione STL: tweet negativi (30 minuti)")+theme_bw()
# fit1 %>%
#   autoplot() + xlab("tempo") +
#   ggtitle("Decomposizione Classica: tweet negativi (30 minuti)")+theme_bw()
# 
# fit2 %>%
#   autoplot() + xlab("tempo") +
#   ggtitle("Decomposizione serie storica tweet neutrali (30 minuti)")
# fit3 %>%
#   autoplot() + xlab("tempo") +
#   ggtitle("Decomposizione serie storica tweet positivi (30 minuti)")

autoplot(neg_ts, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Tempo") + ylab("Numero di tweets") +
  ggtitle("Decomposizone STL: tweet negativi ogni 30 minuti") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))+
  theme_bw()
```

```{r}
autoplot(neg_ts, series="Data") +
  autolayer(trendcycle(fit1), series="Trend") +
  autolayer(seasadj(fit1), series="Seasonally Adjusted") +
  xlab("Tempo") + ylab("Numero di tweets") +
  ggtitle("Decomposizone Classica: tweet negativi ogni 30 minuti") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))+
  theme_bw()

# autoplot(neu_ts, series="Data") +
#   autolayer(trendcycle(fit2), series="Trend") +
#   autolayer(seasadj(fit2), series="Seasonally Adjusted") +
#   xlab("Tempo") + ylab("Numero di tweets") +
#   ggtitle("Frequenza di tweet neutrali ogni 30 minuti") +
#   scale_colour_manual(values=c("gray","blue","red"),
#              breaks=c("Data","Seasonally Adjusted","Trend"))
# autoplot(pos_ts, series="Data") +
#   autolayer(trendcycle(fit3), series="Trend") +
#   autolayer(seasadj(fit3), series="Seasonally Adjusted") +
#   xlab("Tempo") + ylab("Numero di tweets") +
#   ggtitle("Frequenza di tweet positivi ogni 30 minuti") +
#   scale_colour_manual(values=c("gray","blue","red"),
#              breaks=c("Data","Seasonally Adjusted","Trend"))
```

### Modello Fourier + Media mobile
Identifichiamo quanti termini di Fourier da usare

```{r}
# Identificazione della periodicità
# fourier_terms2 <- fourier(neg_ts, K = 2)
# model2 <- tslm(neg_ts ~ fourier_terms2)

fourier_terms5 <- fourier(neg_ts, K = 5)
model5 <- tslm(neg_ts ~ fourier_terms5)

# fourier_terms8 <- fourier(neg_ts, K = 8)
# model8 <- tslm(neg_ts ~ fourier_terms8)
# 
# fourier_terms11<- fourier(neg_ts, K = 11)
# model11 <- tslm(neg_ts ~ fourier_terms11)

# Grafico della serie temporale e della sua approssimazione
# plot.new()
# plot(neg_ts, main = "Periodicità stimata con 2 Termini di Fourier", col = "black", ylab = "Conteggio dei tweet", xlab = "Tempo")+
# lines(fitted(model2), col = "red", lwd = 1.5)
# summary(model2)
```
```{r}
# Estraggo i dati originali e le previsioni
neg_ts_df <- data.frame(time = index(neg_ts), value = coredata(neg_ts))
neg_ts_df$fitted <- fitted(model5)

ggplot(neg_ts_df, aes(x = time)) +
  geom_line(aes(y = value), color = "black") +  # Dati originali
  geom_line(aes(y = fitted), color = "red") +  # Linea della previsione
  labs(title = "Periodicità stimata con 5 Termini di Fourier",
       x = "Tempo",
       y = "Conteggio dei tweet") +
  theme_bw()
```
```{r}
# plot.new()
# plot(neg_ts, main = "Periodicità stimata con 8 Termini di Fourier", col = "black", ylab = "Conteggio dei tweet", xlab = "Tempo")+
# lines(fitted(model8), col = "red", lwd = 1.5)
# summary(model8)
```
```{r}
# plot.new()
# plot(neg_ts, main = "Periodicità stimata con 11 Termini di Fourier", col = "black", ylab = "Conteggio dei tweet", xlab = "Tempo")+
# lines(fitted(model11), col = "red", lwd = 1.5)
# summary(model11)
```

```{r}
autoplot(neg_ts, series="Data") +
  autolayer(ma(neg_ts,24), series="24-MA") +
  autolayer(fitted(model5), series = "Fourier") +
  xlab("30m") + ylab("freq") +
  ggtitle("Decomposizione con modello costruito")+
  scale_colour_manual(values=c("Data"="grey60","24-MA"="red", "Fourier"="blue"),
                      breaks=c("Data","24-MA","Fourier"))+theme_bw()
```

*Modello Completo*

```{r, echo=TRUE}
model_neg =  tslm(neg_ts ~ fourier_terms5 + ma(neg_ts, 24))
summary(model_neg)
```
```{r}
autoplot(neg_ts, series="Data") +
  autolayer(fitted(model_neg), series = "Model") +
  xlab("30m") + ylab("freq") +
  ggtitle("Decomposizione con modello costruito")+
  scale_colour_manual(values=c("Data"="grey60","Model"="red"),
                      breaks=c("Data","Model"))+theme_bw()
```

### Forecast con decomposizione
```{r}
fit %>% forecast(method="arima") %>%
  autoplot() + ylab("freq") + theme_bw()
# fit %>% forecast(method="naive") %>%
#   autoplot() + ylab("freq")
# fit %>% forecast(method="rwdrift") %>%
#   autoplot() + ylab("freq")

```

```{r}
# Dividi i dati in training (80%) e test (20%)
# set.seed(123)  # Per rendere i risultati riproducibili
# 
# 
# train_ts <- head(neg_ts, 268)
# test_ts <- tail(neg_ts, 68)
# 
# # Aggiungi termini di Fourier per il training
# fourier_terms5_train <- fourier(train_ts, K = 5)
# 
# # Crea il modello tslm sul set di training
# model_neg <- tslm(x ~ fourier(x, K = 5) + ma(x, 48), data = as.data.frame(train_ts))
# 
# # Aggiungi termini di Fourier per il test
# fourier_terms5_test <- fourier(test_ts, K = 5)
# 
# # Previsione sul set di test
# predictions <- predict(model_neg, newdata = as.data.frame(test_ts))
# 
# predictions <- ts(predictions, start = 269, frequency = 1)
# autoplot(ts(test_ts, start = 269, frequency = 1), series="Data") +
#   autolayer(predictions, series = "previsioni") +
#   xlab("30m") + ylab("freq") +
#   ggtitle("actuals vs predictions")+
#   scale_colour_manual(values=c("Data"="grey60","previsioni"="red"),
#                       breaks=c("Data","previsioni"))+theme_bw()

```










