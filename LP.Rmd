library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)

# Carichiamo il dataset
dataset <- read_csv2("C:/Users/Utente/Documenti/Dataset.csv")

# Calcoliamo il numero totale di retweet e il numero di tweet per ogni utente
risultati <- dataset %>% 
  group_by(username) %>% 
  summarise(
    tot_retweet = sum(retweetcount, na.rm = TRUE),  # Somma dei retweet
    num_tweet = n()  # Conteggio dei tweet
  ) %>% 
  arrange(desc(tot_retweet)) %>%  # Ordiniamo per numero di retweet in ordine decrescente
  slice_head(n = 5)  # Prendiamo i primi 10 utenti

# Stampiamo i risultati
print(risultati)


# Filtriamo il dataset per i 5 utenti principali
top_users <- risultati$username
dataset_top <- dataset %>% filter(username %in% top_users)

# Aggiungiamo una colonna con il timestamp arrotondato a intervalli di 10 min, 30 min e 1 ora
dataset_top <- dataset_top %>% 
  mutate(
    tweet_time = as.POSIXct(tweetcreatedts, format = "%Y-%m-%d %H:%M:%S"),
    time_10min = floor_date(tweet_time, "10 minutes"),
    time_30min = floor_date(tweet_time, "30 minutes"),
    time_1hour = floor_date(tweet_time, "1 hour")
  )

# Funzione per plottare sentiment e score per un utente
plot_sentiment <- function(data, user, time_col, interval) {
  data %>% 
    group_by(!!sym(time_col), sentiment) %>% 
    summarise(
      avg_score = mean(score, na.rm = TRUE),
      count = n()
    ) %>% 
    ungroup() %>% 
    ggplot(aes(x = !!sym(time_col), y = avg_score, color = sentiment)) +
    geom_line() +
    geom_point(aes(size = count)) +
    labs(
      title = paste("Sentiment Analysis for", user, "every", interval),
      x = "Time",
      y = "Average Score",
      color = "Sentiment",
      size = "Tweet Count"
    ) +
    theme_minimal()
}


# Creazione di grafici ispirati alla foto, basati su intervalli di tempo
for (user in top_users) {
  user_data <- dataset_top %>% filter(username == user)
  
  # Grafico per intervalli di 10 minuti
  g_10min <- ggplot(user_data, aes(x = time_10min, y = score, color = sentiment)) +
    geom_line() +
    scale_color_manual(
      values = c("neg" = "darkred", "neu" = "darkblue", "pos" = "darkgreen")
    ) +
    ggtitle(paste("Time series ogni 10 minuti per", user)) +
    facet_wrap(~ sentiment, scales = "free", ncol = 1) +
    labs(x = "Tempo (10 minuti)", y = "Score", color = "Sentiment") +
    theme_light()
  
  ggsave(paste0("facet_sentiment_10min_", user, ".png"), plot = g_10min)
  
  # Grafico per intervalli di 30 minuti
  g_30min <- ggplot(user_data, aes(x = time_30min, y = score, color = sentiment)) +
    geom_line() +
    scale_color_manual(
      values = c("neg" = "darkred", "neu" = "darkblue", "pos" = "darkgreen")
    ) +
    ggtitle(paste("Time series ogni 30 minuti per", user)) +
    facet_wrap(~ sentiment, scales = "free", ncol = 1) +
    labs(x = "Tempo (30 minuti)", y = "Score", color = "Sentiment") +
    theme_light()
  
  ggsave(paste0("facet_sentiment_30min_", user, ".png"), plot = g_30min)
  
  # Grafico per intervalli di 1 ora
  g_1hour <- ggplot(user_data, aes(x = time_1hour, y = score, color = sentiment)) +
    geom_line() +
    scale_color_manual(
      values = c("neg" = "darkred", "neu" = "darkblue", "pos" = "darkgreen")
    ) +
    ggtitle(paste("Time series ogni 1 ora per", user)) +
    facet_wrap(~ sentiment, scales = "free", ncol = 1) +
    labs(x = "Tempo (1 ora)", y = "Score", color = "Sentiment") +
    theme_light()
  
  ggsave(paste0("facet_sentiment_1hour_", user, ".png"), plot = g_1hour)
}

#Correlazione
# Step 1: Escludere i 5 utenti principali dal dataset
dataset_no_top <- dataset %>% filter(!username %in% top_users)

# Aggregare lo score medio dell'intero dataset (esclusi i top 5 utenti) per intervalli di tempo
aggregated_all <- dataset_no_top %>%
  mutate(
    tweet_time = as.POSIXct(tweetcreatedts, format = "%Y-%m-%d %H:%M:%S"),
    time_10min = floor_date(tweet_time, "10 minutes"),
    time_30min = floor_date(tweet_time, "30 minutes"),
    time_1hour = floor_date(tweet_time, "1 hour")
  ) %>%
  group_by(time_10min, time_30min, time_1hour) %>%
  summarise(score_mean_all = mean(score, na.rm = TRUE), .groups = "drop")

# Step 2: Aggregare lo score medio per i 5 utenti principali per intervalli di tempo
aggregated_top <- dataset_top %>%
  group_by(time_10min, time_30min, time_1hour) %>%
  summarise(score_mean_top = mean(score, na.rm = TRUE), .groups = "drop")

# Step 3: Unire i dataset per i diversi intervalli di tempo
correlation_10min <- merge(aggregated_all %>% select(time_10min, score_mean_all),
                           aggregated_top %>% select(time_10min, score_mean_top),
                           by = "time_10min", all = TRUE)
correlation_30min <- merge(aggregated_all %>% select(time_30min, score_mean_all),
                           aggregated_top %>% select(time_30min, score_mean_top),
                           by = "time_30min", all = TRUE)
correlation_1hour <- merge(aggregated_all %>% select(time_1hour, score_mean_all),
                           aggregated_top %>% select(time_1hour, score_mean_top),
                           by = "time_1hour", all = TRUE)

# Step 4: Calcolare la correlazione per ogni intervallo temporale
cor_10min <- cor(correlation_10min$score_mean_all, correlation_10min$score_mean_top, use = "complete.obs")
cor_30min <- cor(correlation_30min$score_mean_all, correlation_30min$score_mean_top, use = "complete.obs")
cor_1hour <- cor(correlation_1hour$score_mean_all, correlation_1hour$score_mean_top, use = "complete.obs")

# Step 5: Stampare i risultati
cat("Correlazione (10 minuti):", round(cor_10min, 2), "\n")
cat("Correlazione (30 minuti):", round(cor_30min, 2), "\n")
cat("Correlazione (1 ora):", round(cor_1hour, 2), "\n")


#Regressione
# Step 0: Creare le colonne temporali nei dataset
dataset <- dataset %>%
  mutate(
    tweet_time = as.POSIXct(tweetcreatedts, format = "%Y-%m-%d %H:%M:%S"),
    time_10min = floor_date(tweet_time, "10 minutes"),
    time_30min = floor_date(tweet_time, "30 minutes"),
    time_1hour = floor_date(tweet_time, "1 hour")
  )

dataset_top <- dataset_top %>%
  mutate(
    tweet_time = as.POSIXct(tweetcreatedts, format = "%Y-%m-%d %H:%M:%S"),
    time_10min = floor_date(tweet_time, "10 minutes"),
    time_30min = floor_date(tweet_time, "30 minutes"),
    time_1hour = floor_date(tweet_time, "1 hour")
  )

# Step 1:
# Aggregare lo score medio dell'intero dataset (esclusi i top 5 utenti) per intervalli di tempo
aggregated_all <- dataset_no_top %>%
  group_by(time_10min, time_30min, time_1hour) %>%
  summarise(score_mean_all = mean(score, na.rm = TRUE), .groups = "drop")

# Step 2: Aggregare lo score medio per i 5 utenti principali per intervalli di tempo
aggregated_top <- dataset_top %>%
  group_by(time_10min, time_30min, time_1hour) %>%
  summarise(score_mean_top = mean(score, na.rm = TRUE), .groups = "drop")

# Step 3: Creazione di dataset uniti per i diversi intervalli di tempo
correlation_10min <- merge(aggregated_all %>% select(time_10min, score_mean_all),
                           aggregated_top %>% select(time_10min, score_mean_top),
                           by = "time_10min", all = TRUE)
correlation_30min <- merge(aggregated_all %>% select(time_30min, score_mean_all),
                           aggregated_top %>% select(time_30min, score_mean_top),
                           by = "time_30min", all = TRUE)
correlation_1hour <- merge(aggregated_all %>% select(time_1hour, score_mean_all),
                           aggregated_top %>% select(time_1hour, score_mean_top),
                           by = "time_1hour", all = TRUE)

# Step 4: Modelli di regressione lineare
# Intervallo di 10 minuti
model_10min <- lm(score_mean_all ~ score_mean_top, data = correlation_10min)
r2_10min <- summary(model_10min)$r.squared
cat("R^2 (10 minuti):", round(r2_10min, 4), "\n")

# Intervallo di 30 minuti
model_30min <- lm(score_mean_all ~ score_mean_top, data = correlation_30min)
r2_30min <- summary(model_30min)$r.squared
cat("R^2 (30 minuti):", round(r2_30min, 4), "\n")

# Intervallo di 1 ora
model_1hour <- lm(score_mean_all ~ score_mean_top, data = correlation_1hour)
r2_1hour <- summary(model_1hour)$r.squared
cat("R^2 (1 ora):", round(r2_1hour, 4), "\n")

# Stampiamo un riepilogo per ogni modello
cat("\n--- Riepilogo Modelli ---\n")
cat("R^2 (10 minuti):", round(r2_10min, 4), "\n")
cat("R^2 (30 minuti):", round(r2_30min, 4), "\n")
cat("R^2 (1 ora):", round(r2_1hour, 4), "\n")


# I risultati dei valori 𝑅2 calcolati per i modelli di regressione indicano che c'è una correlazione molto debole o praticamente nulla tra lo score medio di tutti gli utenti


#cross-correlazione con le time series
# Step 1: Preparare i dati
# Aggregazione dello score medio per i top 5 utenti e il resto del dataset
aggregated_scores <- dataset %>%
  mutate(
    tweet_time = as.POSIXct(tweetcreatedts, format = "%Y-%m-%d %H:%M:%S"),
    time_10min = floor_date(tweet_time, "10 minutes")
  )

# Score medio del resto del dataset
score_all <- aggregated_scores %>%
  filter(!username %in% top_users) %>%
  group_by(time_10min) %>%
  summarise(mean_score_all = mean(score, na.rm = TRUE))

# Score medio dei top 5 utenti
score_top <- aggregated_scores %>%
  filter(username %in% top_users) %>%
  group_by(time_10min) %>%
  summarise(mean_score_top = mean(score, na.rm = TRUE))

# Merge delle serie temporali
merged_scores <- merge(score_all, score_top, by = "time_10min", all = TRUE)

# Step 2: Creare le serie temporali
ts_all <- ts(merged_scores$mean_score_all, frequency = 6) # Intervalli di 10 minuti
ts_top <- ts(merged_scores$mean_score_top, frequency = 6)

# Step 3: Calcolare la cross-correlazione
ccf(ts_top, ts_all, lag.max = 10, na.action = na.pass)


#Il valore vicino a lag 0 mostra una correlazione positiva debole (intorno a 0.05-0.10).
#Questo indica che non c'è una forte relazione diretta e contemporanea tra i due gruppi.
#Lag negativo (sinistra):
#I valori per lag -1 mostrano correlazioni più alte rispetto a lag positivi.
#Questo suggerisce che il comportamento del resto del dataset (tutti tranne i top 5 utenti) potrebbe precedere e influenzare il comportamento dei top 5 utenti.
#Lag positivo (destra):
#I valori per lag positivi sono deboli e, se significativi, lo sono a un livello molto basso.
#Questo implica che i top 5 utenti hanno una limitata influenza ritardata sul resto del dataset.
#Oscillazioni e pattern:
#Le oscillazioni regolari indicano un pattern ripetitivo che potrebbe suggerire un'eventuale periodicità o sincronizzazione parziale tra i due gruppi.

